{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FUNCTIONS FOR USING .DAT FILES FROM CW3E MET SITES FOR ANALYSIS\n",
    "# By Hillary Beckmeyer (& nan_check fxn augmented from fxn by Ava Cooper)\n",
    "# 25.AUG.2022\n",
    "#\n",
    "# SOME ALTERATIONS MAY BE NEEDED DEPENDENT ON WHAT ASPECTS OF THE DATA ARE BEING USED. THIS IS FOR TEMP (ËšC), \n",
    "# RH (%), RAW BP (mb), MSLP (mb), WIND V1 (M/S), WIND MAX (M/S), 'SLR (W/M^2), PRECIP (mm), AND MIN BATTERY (V).\n",
    "#\n",
    "# ADDED ARE SOME FUNCTIONS FOR SOIL TEMP, PRESSURE, AND MOISTURE (AT DEPTHS OF 5CM, 10CM, 15CM, 20CM, 50CM, AND 100CM).\n",
    "#\n",
    "# CAN BE USED FOR GRAPHING VARIABLES AND COMPARATIVE ANALYSIS. ALSO FOR FINDING THE VARIABLES NEEDED FOR THE CLEARSKY\n",
    "# CALCULATOR.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTING PACKAGES THAT MAY BE NEEDED\n",
    "%matplotlib inline\n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.colors as colors\n",
    "from matplotlib import cm, colors\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pdb, sys, glob, os, shutil, netCDF4, argparse, csv\n",
    "\n",
    "np.set_printoptions(suppress = True, formatter = {'float_kind':'{:0.2f}'.format})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hillarybeckmeyer/Downloads/CW3E_SurfaceMet_Archive\n"
     ]
    }
   ],
   "source": [
    "# set root directory to surface met archive: THIS WILL BE WHEREVER SURF MET DATA LIVES ON YOUR COMPUTER\n",
    "rd = \"~/Downloads/CW3E_SurfaceMet_Archive/\"\n",
    "\n",
    "# THIS IS FOR SETTING THE DIRECTORY FOR ALL FILES (IF THEY'RE IN THE SAME FOLDER)\n",
    "%cd $rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# FUNCTIONS FOR IMPORTING THE FILES AS A PANDAS DATAFRAME\n",
    "\n",
    "def imp(file):\n",
    "    f = pd.read_csv(file, sep = ',', header = None, index_col = 0, skiprows = 4, \\\n",
    "                    na_values = \"NAN\", keep_default_na = False, parse_dates = [0])\n",
    "    print(f.shape)\n",
    "    return f\n",
    "\n",
    "# THERE WAS AN ERROR WITH THE HRD FILE BUT A QUICK FIX WAS TO SKIP THE FIRST 350,000 ROWS. ONLY USE IF YOU NEED\n",
    "# MORE RECENT DATA AND DON'T HAVE THE TIME TO FIND THE ERRORS\n",
    "def hrd(file):\n",
    "    f = pd.read_csv(file, sep = ',', header = None, index_col = 0, skiprows = 350000, \\\n",
    "                    na_values = \"NAN\", keep_default_na = False, parse_dates = [0])\n",
    "    print(f.shape)\n",
    "    return f\n",
    "\n",
    "# CHECKING THE TITLES W/ NO LABELS CUT OUT - NOT FOR GENERAL USE\n",
    "def imp2(file):\n",
    "    f = pd.read_csv(file, sep = ',', header = None, index_col = 0, skiprows = 1, \\\n",
    "                    na_values = \"NAN\", keep_default_na = False, parse_dates = [0])\n",
    "    print(f.shape)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FOR 2 MIN DATA:\n",
    "## MAKING A NaN CHECK FXN TO FILL MISSING TIMESTAMPS & REDUCE # OF VARIABLES IN EACH DATAFRAME\n",
    "\n",
    "# DEFINE FXN nan_check - TAKES 2 MIN DATAFRAME INPUT: SITE_FILE\n",
    "def nan_check(SITE_FILE):\n",
    "    \n",
    "    # picking columns of interest\n",
    "    use = SITE_FILE[[2,5,8,9,12,15,17,23,25]]\n",
    "    # resample to 2 min (data are already 2 min so this fills in missing timestamps)\n",
    "    met = use.resample('2T').mean()\n",
    "    # rename columns\n",
    "    met.columns = ['Temp (\\N{degree sign}C)', 'RH (%)', 'Raw BP (mb)', 'BP MSL (mb)', 'Wnd V1', \\\n",
    "                       'Wnd max', 'SLR (W/m\\N{superscript two})', 'PPT (mm)', 'Min Batt (V)']\n",
    "    \n",
    "    # count the # of NaNs per column\n",
    "    nan_count = met.isnull().sum()\n",
    "    \n",
    "    # find the actual timestamps where any value in the dataframe is NaN\n",
    "    ind = np.where(np.isnan(met))[0]\n",
    "    \n",
    "    # grab those timestamps from the data, drop repeated timestamps \n",
    "    # (occurs when multiple variables are NaN @ the same time)\n",
    "    bad_idx = met.iloc[ind].index.drop_duplicates(keep = 'first')\n",
    "    \n",
    "    # fxn outputs 3 things: dataframe for entire time, array for bad index, & total count of NaNs per var\n",
    "    return(met, bad_idx, nan_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FOR SOIL DATA:\n",
    "## MAKING A NaN CHECK FXN TO FILL MISSING TIMESTAMPS & REDUCE # OF VARIABLES IN EACH DATAFRAME\n",
    "\n",
    "# DEFINE FXN nan_check - TAKES 2 MIN DATAFRAME INPUT: SITE_FILE\n",
    "def nan_check_soil(SITE_FILE):\n",
    "    \n",
    "    # grab columns of interest\n",
    "    use = SITE_FILE[[2,3,4,5,6,7,20,21,22,23,24,25,26,27,28,29,30,31]]\n",
    "    # resample to 2 minutes (data are already 2 min so this fills in missing timestamps)\n",
    "    met = use.resample('2T').mean()\n",
    "    # rename columns\n",
    "    met.columns = ['SoilTmp_5_C_Avg',  'SoilTmp_10_C_Avg', 'SoilTmp_15_C_Avg', 'SoilTmp_20_C_Avg', \\\n",
    "                       'SoilTmp_50_C_Avg','SoilTmp_100_C_Avg', 'PA_uS_5', 'PA_uS_10', 'PA_uS_15', \\\n",
    "                       'PA_uS_20', 'PA_uS_50', 'PA_uS_100', 'VWC_5', 'VWC_10', 'VWC_15', 'VWC_20', \\\n",
    "                       'VWC_50', 'VWC_100']\n",
    "    \n",
    "    # count the # of NaNs per column\n",
    "    nan_count = met.isnull().sum()\n",
    "    \n",
    "    # find the actual timestamps where any value in the dataframe is NaN\n",
    "    ind = np.where(np.isnan(met))[0]\n",
    "    \n",
    "    # grab those timestamps from the data, drop repeated timestamps \n",
    "    # (occurs when multiple variables are NaN @ the same time)\n",
    "    bad_idx = met.iloc[ind].index.drop_duplicates(keep = 'first')\n",
    "    \n",
    "    # fxn outputs 3 things: dataframe for entire time, array for bad index, & total count of NaNs per var\n",
    "    # will most likely only need the first output\n",
    "    return(met, bad_idx, nan_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43228, 27)\n",
      "(154032, 27)\n",
      "(305223, 27)\n",
      "(706965, 27)\n",
      "(696106, 27)\n",
      "(247508, 27)\n",
      "(1033996, 27)\n",
      "(616755, 27)\n",
      "(1032819, 27)\n",
      "(200147, 27)\n",
      "(732692, 27)\n",
      "(968784, 27)\n",
      "(708184, 27)\n",
      "(922978, 27)\n",
      "(987355, 27)\n",
      "(72523, 27)\n",
      "(683644, 27)\n",
      "(234504, 27)\n"
     ]
    }
   ],
   "source": [
    "# SURFACE MET FILE UPLOAD: Use fxn to import file. \n",
    "# CUSTOMIZE SITE AND FILE_NAME BASED ON WHICH SITE(S) YOU ARE LOOKING AT.\n",
    "#SITE = imp('FILE_NAME')\n",
    "\n",
    "GPO = imp('GranitePortal_TwoMin.dat'            )\n",
    "POR = imp('Portola_TwoMin.dat'                  )\n",
    "BVS = imp('BrownsValleySchool_TwoMin.dat'       )\n",
    "DLA = imp('CR1000X_Downieville_RF407_TwoMin.dat')\n",
    "SKY = imp('Skyline_TwoMinWS.dat'                )\n",
    "WPO = imp('CR1000X_WPO_TwoMin.dat'              )\n",
    "WDG = imp('WindyGap_TwoMinWS.dat'               )\n",
    "CAT = imp('CAT_CR1000X_TwoMin.dat'              )\n",
    "NCM = imp('NorthCowMountain_TwoMinWS.dat'       )\n",
    "LBH = imp('LowerBathHouse_TwoMin.dat'           )\n",
    "FRC = imp('FeatherRiverCollege_TwoMin.dat'      )\n",
    "BCC = imp('BoyesCreekCanyon_TwoMinWS 2.dat'     )\n",
    "NBB = imp('CR1000X_NBB_radio_TwoMin.dat'        )\n",
    "HDC = imp('HellsDelight_TwoMinWS.dat'           )\n",
    "PVN = imp('PotterValleyNorth_TwoMinWS.dat'      )\n",
    "HRD = hrd('CR1000X_HRD_Radio_TwoMin.dat'        )\n",
    "DRW = hrd('Deerwood_TwoMinWS.dat'               )\n",
    "SOD = hrd('CR1000X_SOD_TwoMin.dat'              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOIL FILE UPLOAD: Use fxn to import file.\n",
    "\n",
    "# CUSTOMIZE SITE AND FILE_NAME BASED ON WHICH SITE(S) YOU ARE LOOKING AT.\n",
    "# I like to differentiate by adding an \"S\" to the end of the dataframe name if it is a soil file vs. a surf. met. one.\n",
    "# That way, if I'm using both, it's easy to differentiate.\n",
    "\n",
    "#SITE_S = imp('FILE_NAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SURFACE MET DATA: Edit depending on the sites you are looking at, or skip if only viewing one site\n",
    "site_list = [BCC, BVS, CAT, DRW, DLA, FRC, GPO, HDC, HRD, LBH, NBB, NCM, POR, PVN, SKY, SOD, WDG, WPO]\n",
    "site_name = ['BCC', 'BVS', 'CAT', 'DRW', 'DLA', 'FRC', 'GPO', 'HDC', 'HRD', 'LBH', 'NBB', 'NCM', 'POR', \\\n",
    "              'PVN', 'SKY', 'SOD', 'WDG', 'WPO']\n",
    "\n",
    "mets, badidxs, nans = [], [], []\n",
    "for x in range(len(site_list)):\n",
    "    met, badidx, nan = nan_check(site_list[x])\n",
    "    mets.append(met), badidxs.append(badidx), nans.append(nan)\n",
    "\n",
    "for x in range(len(mets)):\n",
    "    mets[x].index.rename(site_name[x], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCC\n",
      "BVS\n",
      "CAT\n",
      "DRW\n",
      "DLA\n",
      "FRC\n",
      "GPO\n",
      "HDC\n",
      "HRD\n",
      "LBH\n",
      "NBB\n",
      "NCM\n",
      "POR\n",
      "PVN\n",
      "SKY\n",
      "SOD\n",
      "WDG\n",
      "WPO\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(mets)):\n",
    "    print(mets[i].index.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SURFACE MET DATA: If just looking at a singular site, and changing index name to 'Time'\n",
    "#SITE_met, SITE_badidx, SITE_nan = nan_check(SITE)\n",
    "#SITE_met.index.rename('Time', inplace = True)\n",
    "\n",
    "WDG_met, WDG_badidx, WDG_nan = nan_check(WDG)\n",
    "WDG_met.index.rename('Time', inplace = True)\n",
    "\n",
    "NCM_met, NCM_badidx, NCM_nan = nan_check(NCM)\n",
    "NCM_met.index.rename('Time', inplace = True)\n",
    "\n",
    "HDC_met, HDC_badidx, HDC_nan = nan_check(HDC)\n",
    "HDC_met.index.rename('Time', inplace = True)\n",
    "\n",
    "DLA_met, DLA_badidx, DLA_nan = nan_check(DLA)\n",
    "DLA_met.index.rename('Time', inplace = True)\n",
    "\n",
    "SKY_met, SKY_badidx, SKY_nan = nan_check(SKY)\n",
    "SKY_met.index.rename('Time', inplace = True)\n",
    "\n",
    "FRC_met, FRC_badidx, FRC_nan = nan_check(FRC)\n",
    "FRC_met.index.rename('Time', inplace = True)\n",
    "\n",
    "DRW_met, DRW_badidx, DRW_nan = nan_check(DRW)\n",
    "DRW_met.index.rename('Time', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOIL DATA: Apply nan_check_soil fxn to site and change index name to 'Time'\n",
    "#SITE_met, SITE_badidx, SITE_nan = nan_check_soil(SITE)\n",
    "#SITE_met.index.rename('Time', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RENAMING THE VARIABLES TO SIMPLIFY\n",
    "# surface met vars\n",
    "tp, rh, bp, msl, v1, wmax, sr, ppt, batt = 'Temp (\\N{degree sign}C)', 'RH (%)', 'Raw BP (mb)', 'BP MSL (mb)', \\\n",
    "    'Wnd V1', 'Wnd max', 'SLR (W/m\\N{superscript two})', 'PPT (mm)', 'Min Batt (V)'\n",
    "\n",
    "# Soil vars\n",
    "t5, t10, t15, t20, t50, t100, p5, p10, p15, p20, p50, p100, m5, m10, m15, m20, m50, m100 = 'SoilTmp_5_C_Avg',  \\\n",
    "    'SoilTmp_10_C_Avg', 'SoilTmp_15_C_Avg', 'SoilTmp_20_C_Avg','SoilTmp_50_C_Avg','SoilTmp_100_C_Avg', 'PA_uS_5',\\\n",
    "    'PA_uS_10', 'PA_uS_15','PA_uS_20', 'PA_uS_50', 'PA_uS_100','VWC_5', 'VWC_10', 'VWC_15', 'VWC_20', \\\n",
    "    'VWC_50', 'VWC_100'\n",
    "\n",
    "## PUTTING VARIABLES INTO LIST\n",
    "#impvals = most important vals for ClearSky model\n",
    "impvals = [tp, rh, sr]\n",
    "vals    = [tp, rh, bp, msl, v1, wmax, sr, ppt, batt]\n",
    "\n",
    "# Separating soil vars by type\n",
    "soil_temp     = [t5, t10, t15, t20, t50, t100] \n",
    "soil_p        = [p5, p10, p15, p20, p50, p100]\n",
    "soil_moisture = [m5, m10, m15, m20, m50, m100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fxn to plot any list of soil variables\n",
    "\n",
    "def allSoil(site, types, word, loc):\n",
    "    plt.rcParams[\"figure.figsize\"] = [20.00, 8.0]\n",
    "    plt.rcParams[\"figure.autolayout\"] = True\n",
    "    fig, ax = plt.subplots(1)\n",
    "    fig.autofmt_xdate()\n",
    "    # run through list of depths, if wanting to plot multiple vars\n",
    "    for i in range(len(types)): \n",
    "        plt.plot(site[types[i]], label = types[i])\n",
    "    plt.xlabel('Date', fontweight = 'bold', fontsize = 16)\n",
    "    plt.ylabel(word, fontweight = 'bold', fontsize = 16)\n",
    "    # can change ymin and ymax depending on season or scope \n",
    "    ax.set_ylim(ymin = 0, ymax = 45)\n",
    "    xfmt = mdates.DateFormatter('%D')\n",
    "    ax.xaxis.set_major_formatter(xfmt)\n",
    "    plt.title(word+loc, fontweight = 'bold', fontsize = '20')\n",
    "    plt.legend(loc = 'upper left')\n",
    "    plt.show()\n",
    "\n",
    "# Fxn specifying soil temp\n",
    "def allTemp(site, loc):\n",
    "    allSoil(site, soil_temp, 'Soil Temp (\\N{degree sign}C)', loc) \n",
    "    # allSoil(site, soil_temp[0:1], 'Soil Temp (\\N{degree sign}C)', loc) \n",
    "    \n",
    "# Fxn specifying soil moisture\n",
    "def allMoisture(site, loc):\n",
    "    allSoil(site, soil_moisture, 'Soil Moisture', loc) \n",
    "    # allSoil(site, soil_moisture[0:1], 'Soil Moisture', loc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'NCMS_met' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-434db8fbc0de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNCMS_met\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"2018-03-30 00:00\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"2022-08-24 07:00\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mallTemp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' @ NCM'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'NCMS_met' is not defined"
     ]
    }
   ],
   "source": [
    "b = NCMS_met[\"2018-03-30 00:00\":\"2022-08-24 07:00\"]\n",
    "allTemp(b, ' @ NCM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticky = np.arange(0, 1300, step = 100)\n",
    "\n",
    "# Fxn to plot variables over a span of time\n",
    "def VARday(var, kind, words):\n",
    "    sns.set_theme(style = \"ticks\", font_scale = 1.25)\n",
    "    sns.despine(offset = 10, trim = True)\n",
    "    ax = plt.gca()\n",
    "    var[kind].plot(color = 'm', figsize = (15,4))\n",
    "    plt.title(str(kind)+': '+words)\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel(kind)\n",
    "    ax.set_ylim(ymin = 0, ymax = 1200)\n",
    "    plt.yticks(ticky)\n",
    "    plt.show()\n",
    "\n",
    "# Fxn specifying solar rad to plot\n",
    "def SLR(var, words):\n",
    "    VARday(var, sr, words)\n",
    "    \n",
    "def graphALL(site, v):\n",
    "    for x in range(len(site)):\n",
    "        VARday((site[x])[v], v, str())\n",
    "    \n",
    "def allSLR(var):\n",
    "    for i in range(len(var)):\n",
    "        SLR((var[i]), str(var[i].index.date[0]))\n",
    "    \n",
    "#finding the maximum value of a variable for a specified timeframe\n",
    "def maxVAR(var):    \n",
    "    var_day = var\n",
    "    h = var_day.shape[0]\n",
    "    \n",
    "    high = 0\n",
    "    time_x = 0\n",
    "    \n",
    "    for x in range(h):\n",
    "        if(var[x] > high):\n",
    "            high = var[x]\n",
    "            time_x = var.index[x]\n",
    "            hour_x = var.index.time[x]\n",
    "            date_x = var.index.date[x]\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "    return high, time_x, hour_x, date_x\n",
    "\n",
    "# Fxn printing the maximum date, time, and value of a variable\n",
    "def prntMAX(var, num, end):\n",
    "    high, time_x, hour_x, date_x = maxVAR(var)\n",
    "    print('Peak', str((GPO_met.columns)[num]), 'is on', date_x, 'at', hour_x, 'UTC:', high, end)\n",
    "    return high, time_x, hour_x, date_x\n",
    "\n",
    "# Fxn specifying solar rad as the variable to print\n",
    "def solar(var):\n",
    "    maxi, ind, hour, date = prntMAX(var, 6, 'W/m\\N{superscript two}')\n",
    "    return maxi, ind, hour, date\n",
    "    \n",
    "# Fxn finding the other variable quantities at max solar rad time\n",
    "def allVAR(var, loc):\n",
    "    h = len(loc.columns)\n",
    "    high, time_x, hour_x, date_x = maxVAR(var)\n",
    "    print(time_x,'\\n')\n",
    "    vals = np.array([], dtype = np.float64)\n",
    "    x = 0\n",
    "    for col in loc.columns: \n",
    "        if x < h:\n",
    "            b = loc.columns[x]\n",
    "            vals = np.append(vals, loc[b][time_x])\n",
    "            print(b, ':', loc[b][time_x])\n",
    "            x += 1\n",
    "        else:\n",
    "            break;\n",
    "            \n",
    "    print('\\n')\n",
    "    return vals\n",
    "\n",
    "def clearsky(site, kind, vals):\n",
    "    A, B, C, D, E, F, G, H, I, J, K = np.array([]), np.array([]), np.array([]), np.array([]), \\\n",
    "    np.array([]), np.array([]), np.array([]), np.array([]), np.array([]), np.array([]), np.array([])\n",
    "    Z = ()\n",
    "    for q in range(len(site)):\n",
    "        a = (site[q])[kind].max()\n",
    "        b = (site[q])[kind].idxmax()\n",
    "        A = np.append(A, a)\n",
    "        B = np.append(B, b)\n",
    "        print('\\n')\n",
    "        print(b)\n",
    "        for r in range(len(vals)):\n",
    "            print(vals[r], '=', (site[q])[vals[r]][b])\n",
    "            if vals[r] == 'Temp (\\N{degree sign}C)':\n",
    "                c = (site[q])[vals[r]][b]\n",
    "                C = np.append(C, c)\n",
    "            elif vals[r] == 'RH (%)':\n",
    "                d = (site[q])[vals[r]][b]\n",
    "                D = np.append(D, d) \n",
    "            elif vals[r] == 'Raw BP (mb)':\n",
    "                e = (site[q])[vals[r]][b]\n",
    "                E = np.append(E, e)\n",
    "            elif vals[r] == 'BP MSL (mb)':\n",
    "                f = (site[q])[vals[r]][b]\n",
    "                F = np.append(F, f)\n",
    "            elif vals[r] == 'Wnd V1':\n",
    "                g = (site[q])[vals[r]][b]\n",
    "                G = np.append(G, g)\n",
    "            elif vals[r] == 'Wnd max':\n",
    "                h = (site[q])[vals[r]][b]\n",
    "                H = np.append(H, h)\n",
    "            elif vals[r] == 'SLR (W/m\\N{superscript two})':\n",
    "                i = (site[q])[vals[r]][b]\n",
    "                I = np.append(I, i)\n",
    "            elif vals[r] == 'PPT (mm)':\n",
    "                j = (site[q])[vals[r]][b]\n",
    "                J = np.append(J, j)\n",
    "            elif vals[r] == 'Min Batt (V)':\n",
    "                k = (site[q])[vals[r]][b]\n",
    "                K = np.append(K, k)\n",
    "            else:\n",
    "                break\n",
    "        Z = (A, B, C, D, E, F, G, H, I, J, K)\n",
    "    return(Z)\n",
    "\n",
    "def csky(site):\n",
    "    x = clearsky(site, sr, impvals)\n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set fxn timespans to ranges you'd like to look at\n",
    "def groups(site):\n",
    "    A = site[\"2022-04-01 07:00\":\"2022-04-10 07:00\"][sr]\n",
    "    B = site[\"2022-04-10 7:00\":\"2022-04-20 07:00\"][sr]\n",
    "    C = site[\"2022-04-20 7:00\":\"2022-04-30 07:00\"][sr]\n",
    "    D = site[\"2022-04-30 7:00\":\"2022-05-09 07:00\"][sr]\n",
    "    G = [A, B, C, D]\n",
    "    return(G)\n",
    "\n",
    "def foursome(group):\n",
    "    for i in range(len(group)):\n",
    "        SLR(group[i], ' from '+str(group[i].index.date[0])+' to '+str(group[i].index.date[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pick specific dates and times you would like to look at for each site\n",
    "print(mets[6].index.name)\n",
    "\n",
    "gpo_whole = mets[6]\n",
    "gpo_set = mets[6][\"2022-04-01 07:00\":\"2022-05-09 18:02\"]\n",
    "\n",
    "gpo0    = mets[6]['2022-04-01 13:00':'2022-04-02 03:00']\n",
    "gpo1    = mets[6]['2022-04-05 13:00':'2022-04-06 03:00']\n",
    "gpo2    = mets[6]['2022-04-06 13:00':'2022-04-07 03:00']\n",
    "gpo3    = mets[6]['2022-04-09 13:00':'2022-04-10 03:00']\n",
    "gpo4    = mets[6]['2022-04-17 13:00':'2022-04-18 03:00']\n",
    "gpo5    = mets[6]['2022-04-25 13:00':'2022-04-26 03:00']\n",
    "gpo6    = mets[6]['2022-04-28 13:00':'2022-04-29 03:00']\n",
    "gpo7    = mets[6]['2022-04-30 13:00':'2022-05-01 03:00']\n",
    "gpo8    = mets[6]['2022-05-01 13:00':'2022-05-02 03:00']\n",
    "gpo9    = mets[6]['2022-05-03 13:00':'2022-05-04 03:00']\n",
    "gpo10   = mets[6]['2022-05-04 13:00':'2022-05-05 03:00']\n",
    "\n",
    "# Making a list combining all the days and the name of the site will come in handy down the line.\n",
    "gpox = [gpo0, gpo1, gpo2, gpo3, gpo4, gpo5, gpo6, gpo7, gpo8, gpo9, gpo10]\n",
    "gpoz = [mets[6].index.name, \"Granite Portal\", gpox]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pick specific dates and times you would like to look at for each site\n",
    "\n",
    "print(mets[12].index.name)\n",
    "\n",
    "por_whole = mets[12]\n",
    "por_set = mets[12]['2022-04-01 07:00':'2022-05-09 18:02']\n",
    "\n",
    "por0    = mets[12]['2022-04-01 13:00':'2022-04-02 03:00']\n",
    "por1    = mets[12]['2022-04-05 13:00':'2022-04-06 03:00']\n",
    "por2    = mets[12]['2022-04-06 13:00':'2022-04-07 03:00']\n",
    "por3    = mets[12]['2022-04-09 13:00':'2022-04-10 03:00']\n",
    "por4    = mets[12]['2022-04-17 13:00':'2022-04-18 03:00']\n",
    "por5    = mets[12]['2022-04-18 13:00':'2022-04-19 03:00']\n",
    "por6    = mets[12]['2022-04-24 13:00':'2022-04-25 03:00']\n",
    "por7    = mets[12]['2022-04-27 13:00':'2022-04-28 03:00']\n",
    "por8    = mets[12]['2022-05-01 13:00':'2022-05-02 03:00']\n",
    "por9    = mets[12]['2022-05-03 13:00':'2022-05-04 03:00']\n",
    "por10   = mets[12]['2022-05-04 13:00':'2022-05-05 03:00']\n",
    "\n",
    "porx = [por0, por1, por2, por3, por4, por5, por6, por7, por8, por9, por10]\n",
    "porz = [mets[12].index.name, \"Portola\", porx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pick specific dates and times you would like to look at for each site\n",
    "\n",
    "print(mets[1].index.name)\n",
    "\n",
    "bvs_whole = mets[1]\n",
    "bvs_set   = mets[1][\"2022-04-01 07:00\":\"2022-05-09 18:02\"]\n",
    "\n",
    "bvs0      = mets[1]['2022-04-01 13:00':'2022-04-02 03:00']\n",
    "bvs1      = mets[1]['2022-04-05 13:00':'2022-04-06 03:00']\n",
    "bvs2      = mets[1]['2022-04-06 13:00':'2022-04-07 03:00']\n",
    "bvs3      = mets[1]['2022-04-09 13:00':'2022-04-10 03:00']\n",
    "bvs4      = mets[1]['2022-04-17 13:00':'2022-04-18 03:00']\n",
    "bvs5      = mets[1]['2022-04-23 13:00':'2022-04-24 03:00']\n",
    "bvs6      = mets[1]['2022-04-26 13:00':'2022-04-27 03:00']\n",
    "bvs7      = mets[1]['2022-04-28 13:00':'2022-04-29 03:00']\n",
    "bvs8      = mets[1]['2022-05-01 13:00':'2022-05-02 03:00']\n",
    "bvs9      = mets[1]['2022-05-03 13:00':'2022-05-04 03:00']\n",
    "bvs10     = mets[1]['2022-05-04 13:00':'2022-05-05 03:00']\n",
    "\n",
    "bvsx = [bvs0, bvs1, bvs2, bvs3, bvs4, bvs5, bvs6, bvs7, bvs8, bvs9, bvs10]\n",
    "bvsz = [mets[1].index.name, \"Browns Valley School\", bvsx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pick specific dates and times you would like to look at for each site\n",
    "\n",
    "print(mets[4].index.name)\n",
    "\n",
    "dla_whole = mets[4]\n",
    "dla_set = mets[4][\"2022-04-01 07:00\":\"2022-05-09 18:02\"]\n",
    "\n",
    "dla0    = mets[4]['2022-04-01 13:00':'2022-04-02 03:00']\n",
    "dla1    = mets[4]['2022-04-05 13:00':'2022-04-06 03:00']\n",
    "dla2    = mets[4]['2022-04-06 13:00':'2022-04-07 03:00']\n",
    "dla3    = mets[4]['2022-04-09 13:00':'2022-04-10 03:00']\n",
    "dla4    = mets[4]['2022-04-17 13:00':'2022-04-18 03:00']\n",
    "dla5    = mets[4]['2022-04-24 13:00':'2022-04-25 03:00']\n",
    "dla6    = mets[4]['2022-05-01 13:00':'2022-05-02 03:00']\n",
    "dla7    = mets[4]['2022-05-03 13:00':'2022-05-04 03:00']\n",
    "dla8    = mets[4]['2022-05-04 13:00':'2022-05-05 03:00']\n",
    "\n",
    "dlax = [dla0, dla1, dla2, dla3, dla4, dla5, dla6, dla7, dla8]\n",
    "dlaz = [mets[4].index.name, \"Downieville\", dlax]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pick specific dates and times you would like to look at for each site\n",
    "\n",
    "print(mets[14].index.name)\n",
    "\n",
    "sky_whole = mets[14]\n",
    "sky_set   = mets[14][\"2022-04-01 07:00\":\"2022-05-09 18:02\"]\n",
    "\n",
    "sky0      = mets[14]['2022-04-01 13:00':'2022-04-02 03:00']\n",
    "sky1      = mets[14]['2022-04-02 13:00':'2022-04-03 03:00']\n",
    "sky2      = mets[14]['2022-04-05 13:00':'2022-04-06 03:00']\n",
    "sky3      = mets[14]['2022-04-06 13:00':'2022-04-07 03:00']\n",
    "sky4      = mets[14]['2022-04-17 13:00':'2022-04-18 03:00']\n",
    "sky5      = mets[14]['2022-04-23 13:00':'2022-04-24 03:00']\n",
    "sky6      = mets[14]['2022-04-26 13:00':'2022-04-27 03:00']\n",
    "sky7      = mets[14]['2022-04-27 13:00':'2022-04-28 03:00']\n",
    "sky8      = mets[14]['2022-05-01 13:00':'2022-05-02 03:00']\n",
    "sky9      = mets[14]['2022-05-03 13:00':'2022-05-04 03:00']\n",
    "sky10     = mets[14]['2022-05-04 13:00':'2022-05-05 03:00']\n",
    "\n",
    "skyx = [sky0, sky1, sky2, sky3, sky4, sky5, sky6, sky7, sky8, sky9, sky10]\n",
    "skyz = [mets[14].index.name, \"Skyline Harvest\", skyx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pick specific dates and times you would like to look at for each site\n",
    "\n",
    "print(mets[-1].index.name)\n",
    "\n",
    "wpo_whole = mets[-1]\n",
    "wpo_set   = mets[-1][\"2022-04-01 07:00\":\"2022-05-09 18:02\"]\n",
    "\n",
    "wpo0      = mets[-1]['2022-04-01 13:00':'2022-04-02 03:00']\n",
    "wpo1      = mets[-1]['2022-04-05 13:00':'2022-04-06 03:00']\n",
    "wpo2      = mets[-1]['2022-04-06 13:00':'2022-04-07 03:00']\n",
    "wpo3      = mets[-1]['2022-04-09 13:00':'2022-04-10 03:00']\n",
    "wpo4      = mets[-1]['2022-04-12 13:00':'2022-04-13 03:00']\n",
    "wpo5      = mets[-1]['2022-04-17 13:00':'2022-04-18 03:00']\n",
    "wpo6      = mets[-1]['2022-04-23 13:00':'2022-04-24 03:00']\n",
    "wpo7      = mets[-1]['2022-04-28 13:00':'2022-04-29 03:00']\n",
    "wpo8      = mets[-1]['2022-05-01 13:00':'2022-05-02 03:00']\n",
    "wpo9      = mets[-1]['2022-05-03 13:00':'2022-05-04 03:00']\n",
    "wpo10     = mets[-1]['2022-05-04 13:00':'2022-05-05 03:00']\n",
    "\n",
    "wpox = [wpo0, wpo1, wpo2, wpo3, wpo4, wpo5, wpo6, wpo7, wpo8, wpo9, wpo10]\n",
    "wpoz = [mets[-1].index.name, \"West Portal\", wpox]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pick specific dates and times you would like to look at for each site\n",
    "\n",
    "print(mets[-2].index.name)\n",
    "\n",
    "wdg_whole = mets[-2]\n",
    "wdg_set   = mets[-2][\"2022-04-01 07:00\":\"2022-05-09 18:02\"]\n",
    "\n",
    "wdg0      = mets[-2]['2022-04-05 13:00':'2022-04-06 03:00']\n",
    "wdg1      = mets[-2]['2022-04-06 13:00':'2022-04-07 03:00']\n",
    "wdg2      = mets[-2]['2022-04-09 13:00':'2022-04-10 03:00']\n",
    "wdg3      = mets[-2]['2022-04-17 13:00':'2022-04-18 03:00']\n",
    "wdg4      = mets[-2]['2022-04-23 13:00':'2022-04-24 03:00']\n",
    "wdg5      = mets[-2]['2022-04-24 13:00':'2022-04-25 03:00']\n",
    "wdg6      = mets[-2]['2022-04-26 13:00':'2022-04-27 03:00']\n",
    "wdg7      = mets[-2]['2022-04-27 13:00':'2022-04-28 03:00']\n",
    "wdg8      = mets[-2]['2022-05-01 13:00':'2022-05-02 03:00']\n",
    "wdg9      = mets[-2]['2022-05-03 13:00':'2022-05-04 03:00']\n",
    "wdg10     = mets[-2]['2022-05-04 13:00':'2022-05-05 03:00']\n",
    "\n",
    "wdgx = [wdg0, wdg1, wdg2, wdg3, wdg4, wdg5, wdg6, wdg7, wdg8, wdg9, wdg10]\n",
    "wdgz = [mets[-2].index.name, \"Windy Gap\", wdgx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pick specific dates and times you would like to look at for each site\n",
    "\n",
    "print(mets[8].index.name)\n",
    "\n",
    "hrd_whole = mets[8]\n",
    "hrd_set   = mets[8][\"2022-04-01 07:00\":\"2022-05-09 18:02\"]\n",
    "\n",
    "hrd0      = mets[8]['2022-04-05 13:00':'2022-04-06 03:00']\n",
    "hrd1      = mets[8]['2022-04-06 13:00':'2022-04-07 03:00']\n",
    "hrd2      = mets[8]['2022-04-08 13:00':'2022-04-09 03:00']\n",
    "hrd3      = mets[8]['2022-04-09 13:00':'2022-04-10 03:00']\n",
    "hrd4      = mets[8]['2022-04-12 13:00':'2022-04-12 21:00']\n",
    "hrd5      = mets[8]['2022-04-17 13:00':'2022-04-18 03:00']\n",
    "hrd6      = mets[8]['2022-04-23 13:00':'2022-04-24 03:00']\n",
    "hrd7      = mets[8]['2022-04-28 13:00':'2022-04-29 03:00']\n",
    "hrd8      = mets[8]['2022-05-01 13:00':'2022-05-01 20:40']\n",
    "hrd9      = mets[8]['2022-05-03 13:00':'2022-05-04 03:00']\n",
    "hrd10     = mets[8]['2022-05-04 13:00':'2022-05-05 03:00']\n",
    "\n",
    "hrdx = [hrd0, hrd1, hrd2, hrd3, hrd4, hrd5, hrd6, hrd7, hrd8, hrd9, hrd10]\n",
    "hrdz = [mets[8].index.name, \"Henness Ridge Drive\", hrdx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pick specific dates and times you would like to look at for each site\n",
    "\n",
    "print(mets[2].index.name)\n",
    "\n",
    "cat_whole = mets[2]\n",
    "cat_set   = mets[2][\"2022-04-01 07:00\":\"2022-05-09 18:02\"]\n",
    "\n",
    "cat0      = mets[2]['2022-04-06 13:00':'2022-04-07 03:00']\n",
    "cat1      = mets[2]['2022-04-07 13:00':'2022-04-08 03:00']\n",
    "cat2      = mets[2]['2022-04-08 13:00':'2022-04-09 03:00']\n",
    "cat3      = mets[2]['2022-04-12 13:00':'2022-04-13 03:00']\n",
    "cat4      = mets[2]['2022-04-13 13:00':'2022-04-14 03:00']\n",
    "cat5      = mets[2]['2022-04-23 13:00':'2022-04-24 03:00']\n",
    "cat6      = mets[2]['2022-04-24 13:00':'2022-04-25 03:00']\n",
    "cat7      = mets[2]['2022-04-25 13:00':'2022-04-26 03:00']\n",
    "cat8      = mets[2]['2022-04-30 13:00':'2022-05-01 03:00']\n",
    "cat9      = mets[2]['2022-05-04 13:00':'2022-05-05 03:00']\n",
    "cat10     = mets[2]['2022-05-06 13:00':'2022-05-07 03:00']\n",
    "\n",
    "catx = [cat0, cat1, cat2, cat3, cat4, cat5, cat6, cat7, cat8, cat9, cat10]\n",
    "catz = [mets[2].index.name, \"Catalina\", catx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pick specific dates and times you would like to look at for each site\n",
    "\n",
    "print(mets[3].index.name)\n",
    "\n",
    "drw_whole = mets[3]\n",
    "\n",
    "drw0      = mets[3]['2022-04-01 13:00':'2022-04-02 03:00']\n",
    "drw1      = mets[3]['2022-04-05 13:00':'2022-04-06 03:00']\n",
    "drw2      = mets[3]['2022-04-06 13:00':'2022-04-07 03:00']\n",
    "drw3      = mets[3]['2022-04-09 13:00':'2022-04-10 03:00']\n",
    "drw4      = mets[3]['2022-04-17 13:00':'2022-04-18 03:00']\n",
    "drw5      = mets[3]['2022-04-24 13:00':'2022-04-25 03:00']\n",
    "drw6      = mets[3]['2022-04-26 13:00':'2022-04-27 03:00']\n",
    "drw7      = mets[3]['2022-04-27 13:00':'2022-04-28 03:00']\n",
    "drw8      = mets[3]['2022-05-01 13:00':'2022-05-02 03:00']\n",
    "drw9      = mets[3]['2022-05-03 13:00':'2022-05-04 03:00']\n",
    "drw10     = mets[3]['2022-05-04 13:00':'2022-05-05 03:00']\n",
    "drw_set   = mets[3][\"2022-04-01 07:00\":\"2022-05-09 18:02\"]\n",
    "\n",
    "drwx = [drw0, drw1, drw2, drw3, drw4, drw5, drw6, drw7, drw8, drw9, drw10]\n",
    "drwz = [mets[3].index.name, \"Deerwood\", drwx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pick specific dates and times you would like to look at for each site\n",
    "\n",
    "print(mets[11].index.name)\n",
    "\n",
    "ncm_whole = mets[11]\n",
    "ncm_set   = mets[11][\"2022-04-01 07:00\":\"2022-05-09 18:02\"]\n",
    "\n",
    "ncm0      = mets[11]['2022-04-01 13:00':'2022-04-02 03:00']\n",
    "ncm1      = mets[11]['2022-04-05 13:00':'2022-04-06 03:00']\n",
    "ncm2      = mets[11]['2022-04-06 13:00':'2022-04-07 03:00']\n",
    "ncm3      = mets[11]['2022-04-09 13:00':'2022-04-10 03:00']\n",
    "ncm4      = mets[11]['2022-04-17 13:00':'2022-04-18 03:00']\n",
    "ncm5      = mets[11]['2022-04-23 13:00':'2022-04-24 03:00']\n",
    "ncm6      = mets[11]['2022-04-24 13:00':'2022-04-25 03:00']\n",
    "ncm7      = mets[11]['2022-04-27 13:00':'2022-04-28 03:00']\n",
    "ncm8      = mets[11]['2022-05-01 13:00':'2022-05-02 03:00']\n",
    "ncm9      = mets[11]['2022-05-03 13:00':'2022-05-04 03:00']\n",
    "ncm10     = mets[11]['2022-05-04 13:00':'2022-05-05 03:00']\n",
    "\n",
    "ncmx = [ncm0, ncm1, ncm2, ncm3, ncm4, ncm5, ncm6, ncm7, ncm8, ncm9, ncm10]\n",
    "ncmz = [mets[11].index.name, \"North Cow Mountain\", ncmx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pick specific dates and times you would like to look at for each site\n",
    "\n",
    "print(mets[9].index.name)\n",
    "\n",
    "lbh_whole = mets[9]\n",
    "lbh_set   = mets[9]['2021-05-01 13:00':'2021-06-01 03:00']\n",
    "\n",
    "lbh0      = mets[9]['2021-05-01 13:00':'2021-05-02 03:00']\n",
    "lbh1      = mets[9]['2021-05-03 13:00':'2021-05-04 03:00']\n",
    "lbh2      = mets[9]['2021-05-04 13:00':'2021-05-05 03:00']\n",
    "lbh3      = mets[9]['2021-05-05 13:00':'2021-05-06 03:00']\n",
    "lbh4      = mets[9]['2021-05-07 13:00':'2021-05-08 03:00']\n",
    "lbh5      = mets[9]['2021-05-08 13:00':'2021-05-09 03:00']\n",
    "lbh6      = mets[9]['2021-05-10 13:00':'2021-05-11 03:00']\n",
    "lbh7      = mets[9]['2021-05-11 13:00':'2021-05-12 03:00']\n",
    "lbh8      = mets[9]['2021-05-12 13:00':'2021-05-13 03:00']\n",
    "lbh9      = mets[9]['2021-05-13 13:00':'2021-05-14 03:00']\n",
    "lbh10     = mets[9]['2021-05-30 13:00':'2021-05-31 03:00']\n",
    "\n",
    "lbhx = [lbh0, lbh1, lbh2, lbh3, lbh4, lbh5, lbh6, lbh7, lbh8, lbh9, lbh10]\n",
    "lbhz = [mets[9].index.name, \"Lower Bathhouse\", lbhx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbhA = mets[9][\"2021-04-21 07:00\":\"2021-05-01 07:00\"][sr]\n",
    "lbhB = mets[9][\"2021-05-01 07:00\":\"2021-05-11 07:00\"][sr] \n",
    "lbhC = mets[9][\"2021-05-11 07:00\":\"2021-05-21 07:00\"][sr] \n",
    "lbhD = mets[9][\"2021-05-21 07:00\":\"2021-05-31 07:00\"][sr] \n",
    "\n",
    "lbhG = [lbhA, lbhB, lbhC, lbhD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pick specific dates and times you would like to look at for each site\n",
    "\n",
    "print(mets[5].index.name)\n",
    "\n",
    "frc_whole = mets[5]\n",
    "frc_set   = mets[5][\"2022-05-01 07:00\":\"2022-06-04 18:02\"]\n",
    "\n",
    "frc0      = mets[5]['2022-05-01 13:00':'2022-05-02 03:00']\n",
    "frc1      = mets[5]['2022-05-03 13:00':'2022-05-04 03:00']\n",
    "frc2      = mets[5]['2022-05-04 13:00':'2022-05-05 03:00']\n",
    "frc3      = mets[5]['2022-05-17 13:00':'2022-05-18 03:00']\n",
    "frc4      = mets[5]['2022-05-19 13:00':'2022-05-20 03:00']\n",
    "frc5      = mets[5]['2022-05-20 13:00':'2022-05-21 03:00']\n",
    "frc6      = mets[5]['2022-05-22 13:00':'2022-05-23 03:00']\n",
    "frc7      = mets[5]['2022-05-23 13:00':'2022-05-24 03:00']\n",
    "frc8      = mets[5]['2022-05-24 13:00':'2022-05-25 03:00']\n",
    "frc9      = mets[5]['2022-05-25 13:00':'2022-05-26 03:00']\n",
    "frc10     = mets[5]['2022-05-31 13:00':'2022-06-01 03:00']\n",
    "\n",
    "frcx = [frc0, frc1, frc2, frc3, frc4, frc5, frc6, frc7, frc8, frc9, frc10]\n",
    "frcz = [mets[5].index.name, \"Feather River College\", frcx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frcA = mets[5][\"2022-05-01 07:00\":\"2022-05-10 07:00\"][sr]\n",
    "frcB = mets[5][\"2022-05-10 07:00\":\"2022-05-20 07:00\"][sr]\n",
    "frcC = mets[5][\"2022-05-20 07:00\":\"2022-05-30 07:00\"][sr]\n",
    "frcD = mets[5][\"2022-05-30 07:00\":\"2022-06-09 07:00\"][sr]\n",
    "frcG = [frcA, frcB, frcC, frcD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pick specific dates and times you would like to look at for each site\n",
    "\n",
    "print(mets[0].index.name)\n",
    "\n",
    "bcc_whole = mets[0]\n",
    "bcc_set   = mets[0][\"2022-04-01 07:00\":\"2022-05-09 18:02\"]\n",
    "\n",
    "bcc0      = mets[0]['2022-04-01 13:00':'2022-04-02 03:00']\n",
    "bcc1      = mets[0]['2022-04-05 13:00':'2022-04-06 03:00']\n",
    "bcc2      = mets[0]['2022-04-06 13:00':'2022-04-07 03:00']\n",
    "bcc3      = mets[0]['2022-04-17 13:00':'2022-04-18 03:00']\n",
    "bcc4      = mets[0]['2022-04-24 13:00':'2022-04-25 03:00']\n",
    "bcc5      = mets[0]['2022-04-26 13:00':'2022-04-27 03:00']\n",
    "bcc6      = mets[0]['2022-04-27 13:00':'2022-04-28 03:00']\n",
    "bcc7      = mets[0]['2022-04-28 13:00':'2022-04-29 03:00']\n",
    "bcc8      = mets[0]['2022-05-01 13:00':'2022-05-02 03:00']\n",
    "bcc9      = mets[0]['2022-05-03 13:00':'2022-05-04 03:00']\n",
    "bcc10     = mets[0]['2022-05-04 13:00':'2022-05-05 03:00']\n",
    "\n",
    "bcc_whole = mets[0][\"2022-04-01 07:00\":\"2022-07-07 00:00\"]\n",
    "\n",
    "bccx = [bcc0, bcc1, bcc2, bcc3, bcc4, bcc5, bcc6, bcc7, bcc8, bcc9, bcc10]\n",
    "bccz = [mets[0].index.name, \"Boyes Creek Canyon\", bccx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pick specific dates and times you would like to look at for each site\n",
    "\n",
    "print(mets[10].index.name)\n",
    "\n",
    "nbb_whole = mets[10]\n",
    "nbb_set   = mets[10][\"2022-04-01 07:00\":\"2022-05-09 18:02\"]\n",
    "\n",
    "nbb0      = mets[10]['2022-04-01 13:00':'2022-04-02 03:00']\n",
    "nbb1      = mets[10]['2022-04-05 13:00':'2022-04-06 03:00']\n",
    "nbb2      = mets[10]['2022-04-06 13:00':'2022-04-07 03:00']\n",
    "nbb3      = mets[10]['2022-04-09 13:00':'2022-04-10 03:00']\n",
    "nbb4      = mets[10]['2022-04-17 13:00':'2022-04-18 03:00']\n",
    "nbb5      = mets[10]['2022-04-23 13:00':'2022-04-24 03:00']\n",
    "nbb6      = mets[10]['2022-04-24 13:00':'2022-04-25 03:00']\n",
    "nbb7      = mets[10]['2022-04-26 13:00':'2022-04-27 03:00']\n",
    "nbb8      = mets[10]['2022-05-01 13:00':'2022-05-02 03:00']\n",
    "nbb9      = mets[10]['2022-05-03 13:00':'2022-05-04 03:00']\n",
    "nbb10     = mets[10]['2022-05-04 13:00':'2022-05-05 03:00']\n",
    "\n",
    "nbbx = [nbb0, nbb1, nbb2, nbb3, nbb4, nbb5, nbb6, nbb7, nbb8, nbb9, nbb10]\n",
    "nbbz = [mets[10].index.name, \"New Bullards Bar Dam\", nbbx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pick specific dates and times you would like to look at for each site\n",
    "\n",
    "print(mets[-3].index.name)\n",
    "\n",
    "sod_whole = mets[-3]\n",
    "sod_set   = mets[-3][\"2022-04-01 07:00\":\"2022-05-09 18:02\"]\n",
    "\n",
    "sod0      = mets[-3]['2022-04-05 13:00':'2022-04-06 03:00']\n",
    "sod1      = mets[-3]['2022-04-06 13:00':'2022-04-07 03:00']\n",
    "sod2      = mets[-3]['2022-04-07 13:00':'2022-04-08 03:00']\n",
    "sod3      = mets[-3]['2022-04-12 13:00':'2022-04-13 03:00']\n",
    "sod4      = mets[-3]['2022-04-13 13:00':'2022-04-14 03:00']\n",
    "sod5      = mets[-3]['2022-04-14 13:00':'2022-04-15 03:00']\n",
    "sod6      = mets[-3]['2022-04-15 13:00':'2022-04-16 03:00']\n",
    "sod7      = mets[-3]['2022-04-29 13:00':'2022-04-30 03:00']\n",
    "sod8      = mets[-3]['2022-05-01 13:00':'2022-05-02 03:00']\n",
    "sod9      = mets[-3]['2022-05-02 13:00':'2022-05-03 03:00']\n",
    "sod10     = mets[-3]['2022-05-04 13:00':'2022-05-05 03:00']\n",
    "\n",
    "sodx = [sod0, sod1, sod2, sod3, sod4, sod5, sod6, sod7, sod8, sod9, sod10]\n",
    "sodz = [mets[-3].index.name, \"Seven Oaks Dam\", sodx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pick specific dates and times you would like to look at for each site\n",
    "\n",
    "print(mets[7].index.name)\n",
    "\n",
    "hdc_whole = mets[7]\n",
    "hdc_set   = mets[7][\"2022-06-03 07:00\":\"2022-07-07 00:00\"]\n",
    "\n",
    "hdc0      = mets[7]['2022-06-06 13:00':'2022-06-07 03:00']\n",
    "hdc1      = mets[7]['2022-06-13 13:00':'2022-06-14 03:00']\n",
    "hdc2      = mets[7]['2022-06-14 13:00':'2022-06-15 03:00']\n",
    "hdc3      = mets[7]['2022-06-20 13:00':'2022-06-21 03:00']\n",
    "hdc4      = mets[7]['2022-06-21 13:00':'2022-06-22 03:00']\n",
    "hdc5      = mets[7]['2022-06-25 13:00':'2022-06-26 03:00']\n",
    "hdc6      = mets[7]['2022-06-26 13:00':'2022-06-27 03:00']\n",
    "hdc7      = mets[7]['2022-06-28 13:00':'2022-06-29 03:00']\n",
    "hdc8      = mets[7]['2022-06-29 13:00':'2022-06-30 03:00']\n",
    "hdc9      = mets[7]['2022-06-30 13:00':'2022-07-01 03:00']\n",
    "hdc10     = mets[7]['2022-07-01 13:00':'2022-07-02 03:00']\n",
    "\n",
    "hdcx = [hdc0, hdc1, hdc2, hdc3, hdc4, hdc5, hdc6, hdc7, hdc8, hdc9, hdc10]\n",
    "hdcz = [mets[7].index.name, \"Hell's Delight Canyon\", hdcx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdcA = mets[7][\"2022-06-03 07:00\":\"2022-06-10 07:00\"][sr]\n",
    "hdcB = mets[7][\"2022-06-10 07:00\":\"2022-06-20 07:00\"][sr]\n",
    "hdcC = mets[7][\"2022-06-20 07:00\":\"2022-06-30 07:00\"][sr]\n",
    "hdcD = mets[7][\"2022-06-30 07:00\":\"2022-07-06 07:00\"][sr]\n",
    "hdcG = [hdcA, hdcB, hdcC, hdcD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pick specific dates and times you would like to look at for each site\n",
    "\n",
    "print(mets[-5].index.name)\n",
    "\n",
    "pvn_whole = mets[-5]\n",
    "pvn_set   = mets[-5][\"2022-06-03 07:00\":\"2022-07-07 00:00\"]\n",
    "\n",
    "pvn0      = mets[-5]['2022-04-01 13:00':'2022-04-02 03:00']\n",
    "pvn1      = mets[-5]['2022-04-05 13:00':'2022-04-06 03:00']\n",
    "pvn2      = mets[-5]['2022-04-06 13:00':'2022-04-07 03:00']\n",
    "pvn3      = mets[-5]['2022-04-09 13:00':'2022-04-10 03:00']\n",
    "pvn4      = mets[-5]['2022-04-17 13:00':'2022-04-18 03:00']\n",
    "pvn5      = mets[-5]['2022-04-24 13:00':'2022-04-25 03:00']\n",
    "pvn6      = mets[-5]['2022-04-26 13:00':'2022-04-27 03:00']\n",
    "pvn7      = mets[-5]['2022-04-27 13:00':'2022-04-28 03:00']\n",
    "pvn8      = mets[-5]['2022-05-01 13:00':'2022-05-02 03:00']\n",
    "pvn9      = mets[-5]['2022-05-03 13:00':'2022-05-04 03:00']\n",
    "pvn10     = mets[-5]['2022-05-04 13:00':'2022-05-05 03:00']\n",
    "\n",
    "pvnx = [pvn0, pvn1, pvn2, pvn3, pvn4, pvn5, pvn6, pvn7, pvn8, pvn9, pvn10]\n",
    "pvnz = [mets[-5].index.name, \"Potter Valley North\", pvnx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a list of all sites and their dates/times.\n",
    "allsites = (gpox, porx, bvsx, dlax, skyx, wpox, wdgx, hrdx, catx, drwx, ncmx, lbhx, frcx, \\\n",
    "            bccx, nbbx, sodx, hdcx, pvnx)\n",
    "allsets = (gpo_set, por_set, bvs_set, dla_set, sky_set, wpo_set, wdg_set, hrd_set, cat_set, \\\n",
    "           drw_set, ncm_set, lbh_set, frc_set, bcc_set, nbb_set, sod_set, hdc_set, pvn_set)\n",
    "allsitez = (gpoz, porz, bvsz, dlaz, skyz, wpoz, wdgz, hrdz, catz, drwz, ncmz, lbhz, frcz, \\\n",
    "            bccz, nbbz, sodz, hdcz, pvnz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making sure they're all the same (i.e., that no sites have been left out)\n",
    "print(len(allsites), len(allsets), len(allsitez))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXAMPLE PLOT:\n",
    "SLR(wdg_whole, ' from '+str(wdg_whole.index.date[0])+' to '+str(wdg_whole.index.date[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#most recent site to look at\n",
    "for i in range(len(allsets)):\n",
    "    SLR(allsets[i], 'at '+str(allsitez[i][1])+' from '+str(allsets[i].index.date[0])+' to '+str(allsets[i].index.date[-1]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#To mass print all subsets/days of solar rad into separate graphs:\n",
    "\n",
    "print(allsitez[7][1])\n",
    "allSLR((allsitez[7])[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Creating lists for specific dates, times, and quantities where solar rad is at its peak.\n",
    "def dvar(locx):\n",
    "    h = []\n",
    "    j = []\n",
    "    k = []\n",
    "    for i in range(len(locx)):\n",
    "        F = (locx[i])[sr].idxmax()\n",
    "        h = np.append(h, F.date())\n",
    "    for i in range(len(locx)):\n",
    "        F = (locx[i])[sr].idxmax()\n",
    "        j = np.append(j, F.time())\n",
    "    for i in range(len(locx)):\n",
    "        F = (locx[i])[sr].idxmax()\n",
    "        k = np.append(k, locx[i][sr].max())\n",
    "    return(h,j,k)\n",
    "\n",
    "## For an easy copy/paste of said list\n",
    "def printy(site):\n",
    "    h, j, k = dvar(site)\n",
    "    for i in range(len(site)):\n",
    "        print(h[i])\n",
    "    print('\\n')\n",
    "    for i in range(len(site)):\n",
    "        print(j[i])\n",
    "    print('\\n')\n",
    "    for i in range(len(site)):\n",
    "        print(k[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "printy(allsites[-1])\n",
    "hi = csky(allsitez[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating percentage error of maximum solar rad. to top 5 values in each day pe = |(m-a)/a| * 100\n",
    "\n",
    "def percerr(name, day, var):\n",
    "    maxi = np.max(day[var])\n",
    "    res = day[var].nlargest(n=5)\n",
    "    #print(res)\n",
    "    avg = pd.DataFrame.mean(res)\n",
    "    per = abs(((maxi-avg)/avg))*100\n",
    "    print(name)\n",
    "    print(\"Max: \", maxi)\n",
    "    #format to three decimal places\n",
    "    form_str = \"{:.3f}\".format(per)\n",
    "    float_val = float(form_str)\n",
    "    print(str(float_val)+'%')\n",
    "    return per\n",
    "\n",
    "def qerr(name, site):\n",
    "    P = []\n",
    "    V = np.array([], dtype = object)\n",
    "    J = []\n",
    "    K = []\n",
    "    L = []\n",
    "    M = []\n",
    "    x = 0\n",
    "    print('Using max. value of timeframe:')\n",
    "    for i in range(len(site)):\n",
    "        j = (i+1)\n",
    "        J = np.append(J, j)\n",
    "        v = name+' Day '+str(i+1)\n",
    "        V = np.append(V, v)\n",
    "        per = percerr(v, site[i], sr)\n",
    "        if per <= 0.33:\n",
    "            x += 1\n",
    "            K = np.append(K, per)\n",
    "            L = np.append(L, x)\n",
    "        elif per > 0.33:\n",
    "            M = np.append(M, per)\n",
    "        P = np.append(P, per)    \n",
    "    pT = np.mean(np.float16(P))\n",
    "    print('Overall percentage error @ '+name+' is:', str(pT)+'%\\n')\n",
    "    return(name, V, P, pT, J, K, L, M)\n",
    "\n",
    "def mpercerr(name, day, var, mod):\n",
    "    res = day[var].nlargest(n=5)\n",
    "    #print(res)\n",
    "    avg = pd.DataFrame.mean(res)\n",
    "    per = abs(((mod-avg)/avg))*100\n",
    "    print(name)\n",
    "    print(\"Model: \", mod)\n",
    "    #format to three decimal places\n",
    "    form_str = \"{:.3f}\".format(per)\n",
    "    float_val = float(form_str)\n",
    "    print(str(float_val)+'%')\n",
    "    return per\n",
    "        \n",
    "def mqerr(name, site, model):\n",
    "    Q = []\n",
    "    V = np.array([], dtype = object)\n",
    "    J = []\n",
    "    print('Using the model from ClearSky:')\n",
    "    for i in range(len(site)):\n",
    "        j = (i+1)\n",
    "        J = np.append(J, j)\n",
    "        v = name+' Day '+str(i+1)\n",
    "        V = np.append(V, v)\n",
    "        per = mpercerr(v, site[i], sr, model[i])\n",
    "        Q = np.append(Q, per)\n",
    "    qT = np.mean(np.float16(Q))\n",
    "    print('Overall percentage error @ '+name+' in relation to ClearSky model is:', str(qT)+'%\\n')\n",
    "    return(name, V, Q, qT, J)\n",
    "\n",
    "def Perplt(site, x):\n",
    "    if(site[2]).max() > 0.33: \n",
    "        plt.bar(site[6], site[5], color = ('blue','cornflowerblue','lightgreen','gold','orange','tomato'))\n",
    "        plt.xticks(range(len(site[6])+1))\n",
    "    else:\n",
    "        plt.bar(site[4], site[2], color = ('blue','cornflowerblue','lightgreen','gold','orange','tomato'))\n",
    "        plt.xticks(range(len(site[2])+1))\n",
    "    plt.title(str(site[0])+' Solar Rad Percentage Errors', fontweight = 'bold', fontsize = '18')\n",
    "    plt.ylabel('Percentage Error (%)', fontweight = 'bold', fontsize = '17')\n",
    "    plt.yticks(levels)\n",
    "    plt.show()\n",
    "    print('Where PE = |(M-A)/A|*100, the errors are:', np.float64(site[2]))\n",
    "    if(np.array(site[7]).size > 0):\n",
    "        print('At '+str(site[0])+', these percentage values were anomalous to the other days:'+str(site[7]))\n",
    "    else:\n",
    "        return\n",
    "    \n",
    "def MPerplt(site, x):\n",
    "    plt.bar(site[4], site[2], color = ('blue','cornflowerblue','lightgreen','gold','orange','tomato'))\n",
    "    plt.title(str(site[0])+' Solar Rad Percentage Errors w/ Model', fontweight = 'bold', fontsize = '18')\n",
    "    plt.xlabel(str(x), fontweight = 'bold', fontsize = '17')\n",
    "    plt.xticks(range(len(site[2])+1))\n",
    "    plt.ylabel('Percentage Error (%)', fontweight = 'bold', fontsize = '17')\n",
    "    plt.show()\n",
    "    print('Where PE = |(M-A)/A|*100, the errors are:', np.float64(site[2]))\n",
    "    \n",
    "def twodec(value):\n",
    "    form_str = \"{:.2f}\".format(value)\n",
    "    fl_val = float(form_str)\n",
    "\n",
    "    return(fl_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levels = np.arange(0, 0.35, step = 0.05)\n",
    "mgpo = [881, 893, 900, 926, 940, 962, 984, 970, 980, 977, 982]\n",
    "\n",
    "gran = qerr('GPO', gpox)\n",
    "granm = mqerr('GPO', gpox, mgpo)\n",
    "\n",
    "Perplt(gran, 'Days')\n",
    "MPerplt(granm, 'Days')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "levels = np.arange(0, 0.35, step = 0.05)\n",
    "mpor = [886, 901, 910, 925, 949, 947, 967, 963, 983, 986, 982]\n",
    "\n",
    "port = qerr('POR', porx)\n",
    "portm = mqerr('POR', porx, mpor)\n",
    "\n",
    "Perplt(port, 'Days')\n",
    "MPerplt(portm, 'Days')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "levels = np.arange(0, 0.35, step = 0.05)\n",
    "mbvs = [844, 878, 880, 905, 907, 926, 924, 938, 949, 955, 944]\n",
    "\n",
    "brow = qerr('BVS', bvsx)\n",
    "browm = mqerr('BVS', bvsx, mbvs)\n",
    "\n",
    "Perplt(brow, 'Days')\n",
    "MPerplt(browm, 'Days')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "levels = np.arange(0, 0.35, step = 0.05)\n",
    "mdla = [872, 883, 892, 903, 925, 951, 974, 976, 967]\n",
    "\n",
    "down = qerr('DLA', dlax)\n",
    "downm = mqerr('DLA', dlax, mdla)\n",
    "\n",
    "Perplt(down, 'Days')\n",
    "MPerplt(downm, 'Days')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "levels = np.arange(0, 0.35, step = 0.05)\n",
    "msky = [863, 871, 852, 890, 917, 929, 944, 943, 969, 962, 956]\n",
    "\n",
    "skyl = qerr('SKY', skyx)\n",
    "skylm = mqerr('SKY', skyx, msky)\n",
    "print(skyl[5])\n",
    "print(skyl[6])\n",
    "## NOTE: 3, 5, & 7 high error\n",
    "print(str(twodec(skyl[7][0]))+'%', str(twodec(skyl[7][1]))+'%', str(twodec(skyl[7][2]))+'%')\n",
    "\n",
    "Perplt(skyl, 'Days')\n",
    "MPerplt(skylm, 'Days')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mwest = [864, 880, 886, 906, 937, 918, 949, 966, 949, 979, 970]\n",
    "\n",
    "west = qerr('WPO', wpox)\n",
    "westm = mqerr('WPO', wpox, mwest)\n",
    "\n",
    "Perplt(west, 'Days')\n",
    "MPerplt(westm, 'Days')\n",
    " \n",
    "#print(west[5])\n",
    "#westb = (west[2])[np.arange(len(west[2]))!=3]  # b = array([9, 8, 7, 5, 4, 3, 2, 1, 0])\n",
    "#print(westb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mwdy = [892, 883, 911, 916, 939, 942, 935, 945, 957, 976, 959]\n",
    "\n",
    "wind = qerr('WDG', wdgx)\n",
    "windm = mqerr('WDG', wdgx, mwdy)\n",
    "\n",
    "Perplt(wind, 'Days')\n",
    "MPerplt(windm, 'Days')\n",
    "\n",
    "print(\"{:.3f}\".format((wind[2])[3])+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mhen = [913, 927, 941, 945, 979, 972, 982, 1006, 994, 1000, 1001]\n",
    "\n",
    "henn = qerr('HRD', hrdx)\n",
    "hennm = mqerr('HRD', hrdx, mhen)\n",
    "\n",
    "Perplt(henn, 'Days')\n",
    "MPerplt(hennm, 'Days')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcat = [893, 937, 944, 957, 953, 955, 978, 970, 957, 962, 962]\n",
    "\n",
    "cata = qerr('CAT', catx)\n",
    "catam = mqerr('CAT', catx, mcat)\n",
    "\n",
    "Perplt(cata, 'Days')\n",
    "MPerplt(catam, 'Days')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdrw = 855, 872, 879, 894, 939, 933, 933, 937, 962, 962, 943\n",
    "\n",
    "deer = qerr('DRW', drwx)\n",
    "deerm = mqerr('DRW', drwx, mdrw)\n",
    "\n",
    "Perplt(deer, 'Days')\n",
    "MPerplt(deerm, 'Days')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mncm = 864, 896, 893, 912, 921, 952, 949, 955, 963, 976, 963\n",
    "\n",
    "cow = qerr('NCM', ncmx)\n",
    "cowm = mqerr('NCM', ncmx, mncm)\n",
    "\n",
    "Perplt(cow, 'Days')\n",
    "MPerplt(cowm, 'Days')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlbh = 993, 995, 984, 977, 993, 1014, 1011, 1004, 1006, 998, 1017\n",
    "\n",
    "bath = qerr('LBH', lbhx)\n",
    "bathm = mqerr('LBH', lbhx, mlbh)\n",
    "\n",
    "Perplt(bath, 'Days')\n",
    "MPerplt(bathm, 'Days')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfrc = 969, 967, 969, 986, 978, 1018, 993, 987, 996, 973, 1008\n",
    "\n",
    "feat = qerr('FRC', frcx)\n",
    "featm = mqerr('FRC', frcx, mfrc)\n",
    "\n",
    "Perplt(feat, 'Days')\n",
    "MPerplt(featm, 'Days')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbcc = 849, 880, 860, 930, 941, 937, 942, 949, 936, 945, 940\n",
    "\n",
    "boy = qerr('BCC', bccx)\n",
    "boym = mqerr('BCC', bccx, mbcc)\n",
    "\n",
    "Perplt(boy, 'Days')\n",
    "MPerplt(boym, 'Days')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnbb = 858, 866, 886, 900, 913, 932, 946, 946, 977, 962, 957\n",
    "\n",
    "bar = qerr('NBB', nbbx)\n",
    "barm = mqerr('NBB', nbbx, mnbb)\n",
    "\n",
    "Perplt(bar, 'Days')\n",
    "MPerplt(barm, 'Days')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msod = 914, 929, 961, 989, 988, 982, 970, 990, 992, 980, 1006\n",
    "\n",
    "sev = qerr('SOD', sodx)\n",
    "sevm = mqerr('SOD', sodx, msod)\n",
    "\n",
    "Perplt(sev, 'Days')\n",
    "MPerplt(sevm, 'Days')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mhdc = 979, 999, 994, 992, 1000, 983, 1005, 983, 987, 975, 974\n",
    "\n",
    "hell = qerr('HDC', hdcx)\n",
    "hellm = mqerr('HDC', hdcx, mhdc)\n",
    "\n",
    "Perplt(hell, 'Days')\n",
    "MPerplt(hellm, 'Days')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpvn = 843, 875, 866, 901, 920, 931, 924, 932, 935, 943, 949\n",
    "\n",
    "pot = qerr('PVN', pvnx)\n",
    "potm = mqerr('PVN', pvnx, mpvn)\n",
    "\n",
    "Perplt(pot, 'Days')\n",
    "MPerplt(potm, 'Days')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allmeans = [gran, port, brow, down, skyl, west, wind, henn, cata, deer, cow, bath, feat, boy, bar, sev, hell, pot]\n",
    "mallmeans= [granm, portm, browm, downm, skylm, westm, windm, hennm, catam, deerm, cowm, bathm, featm, \\\n",
    "            boym, barm, sevm, hellm, potm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allsite(site):\n",
    "    g = []\n",
    "    h = []\n",
    "    j = []\n",
    "    k = []\n",
    "    for i in range(len(site)):\n",
    "        if(site[i][3] < 50):\n",
    "            g = np.append(g, site[i][0])\n",
    "            h = np.append(h, site[i][3])\n",
    "        else:\n",
    "            j = np.append(j, site[i][0])\n",
    "            k = np.append(k, site[i][3])\n",
    "    return(g, h, j, k)   \n",
    "\n",
    "def plotALL(site, z):\n",
    "    x, y, a, b = allsite(site)\n",
    "    plt.bar(x, y, color = ('blue','cornflowerblue','lightgreen','gold','orange','tomato'))\n",
    "    plt.title('All Sites Solar Rad Percentage Errors'+str(z), fontweight = 'bold', fontsize = '18')\n",
    "    plt.xlabel('Site Locations', fontweight = 'bold', fontsize = '17')\n",
    "    plt.xticks(x)\n",
    "    plt.ylabel('Percentage Error (%)', fontweight = 'bold', fontsize = '17')\n",
    "    plt.show()\n",
    "    print('Where PE = |(M-A)/A|*100, the errors are:', np.float64(y))\n",
    "    if(np.array(a).size > 0):\n",
    "        print('At '+str(a)+', these percentage values were anomalous to the other days:'+str(b))\n",
    "    else:\n",
    "        return\n",
    "#    \n",
    "def anom(sites, z):\n",
    "    x, y, a, b = allsite(sites)\n",
    "    plt.bar(a, b, color = ('blue','cornflowerblue','lightgreen','gold','orange','tomato'))\n",
    "    plt.title('All Sites Solar Rad Percentage Errors'+str(z), fontweight = 'bold', fontsize = '18')\n",
    "    plt.xlabel('Site Locations', fontweight = 'bold', fontsize = '17')\n",
    "    plt.xticks(x)\n",
    "    plt.ylabel('Percentage Error (%)', fontweight = 'bold', fontsize = '17')\n",
    "    plt.show()\n",
    "    print('Where PE = |(M-A)/A|*100, the errors are:', np.float64(b))\n",
    "    if(np.array(a).size > 0):\n",
    "        print('At '+str(a)+', these percentage values were anomalous to the other days:'+str(b))\n",
    "    else:\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotALL(allmeans, ' w/o model')\n",
    "plotALL(mallmeans, ' w/ Clearsky model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly = [windm, cowm, featm, sevm]\n",
    "anom(anomaly, ' w/ Anomalous Solar Rad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(hrdx)):\n",
    "    print(str(hrdx[i].index.date[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = len(hrd0)\n",
    "w = len(impvals)\n",
    "v = len(henny)\n",
    "print(z,w,v)\n",
    "\n",
    "for a in range(z):\n",
    "    if hrd0[sr][a] == hrd0[sr].max():\n",
    "        for c in range(w):\n",
    "            print(hrd0[sr].idxmax())\n",
    "            print(hrd0[impvals[c]][b])\n",
    "    else:\n",
    "            continue\n",
    "            \n",
    "print(hrd0[sr].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrd4y      = mets[8]['2022-04-12 13:00':'2022-04-13 03:00']\n",
    "hrd8y      = mets[8]['2022-05-01 13:00':'2022-05-02 03:00']\n",
    "\n",
    "hrdy = [hrd0, hrd1, hrd2, hrd3, hrd4y, hrd5, hrd6, hrd7, hrd8y, hrd9, hrd10]\n",
    "\n",
    "allsitesy = ()\n",
    "allsets = ()\n",
    "allsitesy = (gpox, porx, bvsx, dlax, skyx, wpox, wdgx, hrdy, catx, drwx, ncmx, lbhx, frcx, \\\n",
    "            bccx, nbbx, sodx, hdcx, pvnx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates\n",
    "\n",
    "def allday(site, loc):\n",
    "    times = pd.date_range('2015-05-01 06:00', periods = 421, freq = '2T')\n",
    "\n",
    "    plt.rcParams[\"figure.figsize\"] = [20.00, 8.0]\n",
    "    plt.rcParams[\"figure.autolayout\"] = True\n",
    "    fig, ax = plt.subplots(1)\n",
    "    fig.autofmt_xdate()\n",
    "    for i in range(len(site)): \n",
    "        plt.plot(times, site[i][sr])\n",
    "    plt.xlabel('Time of Day (PDT)', fontweight = 'bold', fontsize = 16)\n",
    "    plt.ylabel('Solar Radiation (W/m\\N{superscript two})', fontweight = 'bold', fontsize = 16)\n",
    "    xfmt = mdates.DateFormatter('%H:%M')\n",
    "    ax.xaxis.set_major_formatter(xfmt)\n",
    "    plt.title(str(loc)+' Solar Rad', fontweight = 'bold', fontsize = '20')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(allsites)):\n",
    "    allday(allsitesy[i], allsitez[i][1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
